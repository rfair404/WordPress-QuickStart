name: Performance Monitoring

on:
  schedule:
    # Run weekly on Sundays at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      url:
        description: 'URL to test (optional, defaults to staging)'
        required: false
        type: string

env:
  NODE_VERSION: '18'
  LIGHTHOUSE_RUNS: 3

jobs:
  lighthouse-audit:
    name: Lighthouse Performance Audit
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Lighthouse CLI
        run: npm install -g @lhci/cli@0.12.x lighthouse

      - name: Create Lighthouse config
        run: |
          cat > lighthouserc.json << 'EOF'
          {
            "ci": {
              "numberOfRuns": ${{ env.LIGHTHOUSE_RUNS }},
              "settings": {
                "chromeFlags": "--no-sandbox --headless"
              },
              "assert": {
                "assertions": {
                  "categories:performance": ["warn", {"minScore": 0.7}],
                  "categories:accessibility": ["error", {"minScore": 0.9}],
                  "categories:best-practices": ["warn", {"minScore": 0.8}],
                  "categories:seo": ["warn", {"minScore": 0.8}]
                }
              },
              "collect": {
                "url": ["${{ github.event.inputs.url || secrets.STAGING_URL }}/"],
                "startServerCommand": null
              },
              "upload": {
                "target": "temporary-public-storage"
              }
            }
          }
          EOF

      - name: Run Lighthouse audit
        id: lighthouse
        run: |
          lhci autorun --config=lighthouserc.json > lighthouse-results.txt 2>&1 || true

          # Extract key metrics
          PERFORMANCE=$(grep -o 'Performance: [0-9.]*' lighthouse-results.txt | tail -1 | cut -d' ' -f2 || echo "N/A")
          ACCESSIBILITY=$(grep -o 'Accessibility: [0-9.]*' lighthouse-results.txt | tail -1 | cut -d' ' -f2 || echo "N/A")
          BEST_PRACTICES=$(grep -o 'Best Practices: [0-9.]*' lighthouse-results.txt | tail -1 | cut -d' ' -f2 || echo "N/A")
          SEO=$(grep -o 'SEO: [0-9.]*' lighthouse-results.txt | tail -1 | cut -d' ' -f2 || echo "N/A")

          echo "PERFORMANCE_SCORE=$PERFORMANCE" >> $GITHUB_OUTPUT
          echo "ACCESSIBILITY_SCORE=$ACCESSIBILITY" >> $GITHUB_OUTPUT
          echo "BEST_PRACTICES_SCORE=$BEST_PRACTICES" >> $GITHUB_OUTPUT
          echo "SEO_SCORE=$SEO" >> $GITHUB_OUTPUT

          # Check if any score is below threshold
          if (( $(echo "$PERFORMANCE < 0.7" | bc -l) )); then
            echo "PERFORMANCE_ISSUE=true" >> $GITHUB_OUTPUT
          fi
          if (( $(echo "$ACCESSIBILITY < 0.9" | bc -l) )); then
            echo "ACCESSIBILITY_ISSUE=true" >> $GITHUB_OUTPUT
          fi

      - name: Store Lighthouse report
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-report
          path: |
            .lighthouseci/
            lighthouse-results.txt
          retention-days: 30

      - name: Create performance issue
        uses: actions/github-script@v6
        if: steps.lighthouse.outputs.PERFORMANCE_ISSUE == 'true' || steps.lighthouse.outputs.ACCESSIBILITY_ISSUE == 'true'
        with:
          script: |
            const performance = '${{ steps.lighthouse.outputs.PERFORMANCE_SCORE }}';
            const accessibility = '${{ steps.lighthouse.outputs.ACCESSIBILITY_SCORE }}';
            const bestPractices = '${{ steps.lighthouse.outputs.BEST_PRACTICES_SCORE }}';
            const seo = '${{ steps.lighthouse.outputs.SEO_SCORE }}';

            let body = '## üìä Performance Audit Results\n\n';
            body += `**Test URL:** \`${{ github.event.inputs.url || secrets.STAGING_URL }}\`\n`;
            body += `**Date:** ${new Date().toISOString().split('T')[0]}\n\n`;

            body += '### Lighthouse Scores\n\n';
            body += `| Category | Score | Status |\n`;
            body += `|----------|-------|--------|\n`;
            body += `| Performance | ${performance} | ${performance < 0.7 ? '‚ùå Below threshold (0.7)' : '‚úÖ Good'} |\n`;
            body += `| Accessibility | ${accessibility} | ${accessibility < 0.9 ? '‚ùå Below threshold (0.9)' : '‚úÖ Good'} |\n`;
            body += `| Best Practices | ${bestPractices} | ${bestPractices < 0.8 ? '‚ö†Ô∏è Below threshold (0.8)' : '‚úÖ Good'} |\n`;
            body += `| SEO | ${seo} | ${seo < 0.8 ? '‚ö†Ô∏è Below threshold (0.8)' : '‚úÖ Good'} |\n\n`;

            body += '### Action Items\n\n';
            if (performance < 0.7) {
              body += '#### üêå Performance Issues\n';
              body += '- Review bundle size and optimize JavaScript/CSS\n';
              body += '- Implement image optimization and lazy loading\n';
              body += '- Enable caching and compression\n';
              body += '- Consider CDN implementation\n\n';
            }

            if (accessibility < 0.9) {
              body += '#### ‚ôø Accessibility Issues\n';
              body += '- Review color contrast ratios\n';
              body += '- Add missing alt text for images\n';
              body += '- Ensure proper heading structure\n';
              body += '- Test with screen readers\n\n';
            }

            body += '### Full Report\n';
            body += 'Download the full Lighthouse report from the workflow artifacts.\n\n';
            body += '> This issue was automatically created by the performance monitoring workflow.';

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üìä Performance audit failed - ${new Date().toISOString().split('T')[0]}`,
              body: body,
              labels: ['performance', 'monitoring']
            });

  # Load testing with simple URL checks
  load-test:
    name: Basic Load Test
    runs-on: ubuntu-latest
    needs: lighthouse-audit
    steps:
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Artillery
        run: npm install -g artillery@latest

      - name: Create load test config
        run: |
          cat > load-test.yml << 'EOF'
          config:
            target: '${{ github.event.inputs.url || secrets.STAGING_URL }}'
            phases:
              - duration: 60
                arrivalRate: 5
                name: "Warm up"
              - duration: 120
                arrivalRate: 10
                name: "Sustained load"
              - duration: 60
                arrivalRate: 20
                name: "Peak load"
            http:
              timeout: 30
          scenarios:
            - name: "Homepage"
              weight: 50
              flow:
                - get:
                    url: "/"
            - name: "Sample page"
              weight: 30
              flow:
                - get:
                    url: "/sample-page"
            - name: "Shop"
              weight: 20
              flow:
                - get:
                    url: "/shop"
          EOF

      - name: Run load test
        id: loadtest
        run: |
          artillery run load-test.yml --output load-test-results.json > load-test-output.txt 2>&1 || true

          # Extract key metrics
          MEAN_RESPONSE=$(grep -o 'response_time.*mean: [0-9.]*' load-test-output.txt | tail -1 | awk '{print $3}' || echo "N/A")
          P95_RESPONSE=$(grep -o 'response_time.*p95: [0-9.]*' load-test-output.txt | tail -1 | awk '{print $3}' || echo "N/A")
          ERROR_RATE=$(grep -o 'codes.*2xx: [0-9]*' load-test-output.txt | tail -1 | awk '{print $3}' || echo "0")

          echo "MEAN_RESPONSE_TIME=$MEAN_RESPONSE" >> $GITHUB_OUTPUT
          echo "P95_RESPONSE_TIME=$P95_RESPONSE" >> $GITHUB_OUTPUT
          echo "ERROR_RATE=$ERROR_RATE" >> $GITHUB_OUTPUT

          # Check for performance issues
          if (( $(echo "$MEAN_RESPONSE > 2000" | bc -l) )); then
            echo "SLOW_RESPONSE=true" >> $GITHUB_OUTPUT
          fi

      - name: Store load test results
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results
          path: |
            load-test-results.json
            load-test-output.txt
          retention-days: 30

      - name: Create load test issue
        uses: actions/github-script@v6
        if: steps.loadtest.outputs.SLOW_RESPONSE == 'true'
        with:
          script: |
            const meanResponse = '${{ steps.loadtest.outputs.MEAN_RESPONSE_TIME }}';
            const p95Response = '${{ steps.loadtest.outputs.P95_RESPONSE_TIME }}';
            const errorRate = '${{ steps.loadtest.outputs.ERROR_RATE }}';

            let body = '## üö® Load Test Performance Issue\n\n';
            body += `**Test URL:** \`${{ github.event.inputs.url || secrets.STAGING_URL }}\`\n`;
            body += `**Date:** ${new Date().toISOString().split('T')[0]}\n\n`;

            body += '### Load Test Results\n\n';
            body += `| Metric | Value | Threshold | Status |\n`;
            body += `|--------|-------|-----------|--------|\n`;
            body += `| Mean Response Time | ${meanResponse}ms | <2000ms | ${meanResponse > 2000 ? '‚ùå Slow' : '‚úÖ Good'} |\n`;
            body += `| 95th Percentile | ${p95Response}ms | <5000ms | ${p95Response > 5000 ? '‚ùå Slow' : '‚úÖ Good'} |\n`;
            body += `| Successful Requests | ${errorRate} | >95% | ${errorRate < 0.95 ? '‚ùå High errors' : '‚úÖ Good'} |\n\n`;

            body += '### Recommendations\n';
            body += '- Review server resources and scaling configuration\n';
            body += '- Optimize database queries and caching\n';
            body += '- Consider implementing a CDN\n';
            body += '- Review third-party integrations for performance impact\n\n';
            body += '> This issue was automatically created by the load testing workflow.';

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® Load test performance degradation - ${new Date().toISOString().split('T')[0]}`,
              body: body,
              labels: ['performance', 'load-testing', 'monitoring']
            });

  # Generate performance report
  report:
    name: Generate Performance Report
    runs-on: ubuntu-latest
    needs: [lighthouse-audit, load-test]
    if: always()
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Generate performance summary
        run: |
          echo "# üìä Weekly Performance Report" > performance-report.md
          echo "" >> performance-report.md
          echo "**Generated:** $(date)" >> performance-report.md
          echo "**URL:** ${{ github.event.inputs.url || secrets.STAGING_URL }}" >> performance-report.md
          echo "" >> performance-report.md

          echo "## Lighthouse Audit" >> performance-report.md
          echo "- Performance: ${{ needs.lighthouse-audit.outputs.PERFORMANCE_SCORE || 'N/A' }}" >> performance-report.md
          echo "- Accessibility: ${{ needs.lighthouse-audit.outputs.ACCESSIBILITY_SCORE || 'N/A' }}" >> performance-report.md
          echo "- Best Practices: ${{ needs.lighthouse-audit.outputs.BEST_PRACTICES_SCORE || 'N/A' }}" >> performance-report.md
          echo "- SEO: ${{ needs.lighthouse-audit.outputs.SEO_SCORE || 'N/A' }}" >> performance-report.md
          echo "" >> performance-report.md

          echo "## Load Test Results" >> performance-report.md
          echo "- Mean Response Time: ${{ needs.load-test.outputs.MEAN_RESPONSE_TIME || 'N/A' }}ms" >> performance-report.md
          echo "- 95th Percentile: ${{ needs.load-test.outputs.P95_RESPONSE_TIME || 'N/A' }}ms" >> performance-report.md
          echo "- Success Rate: ${{ needs.load-test.outputs.ERROR_RATE || 'N/A' }}" >> performance-report.md
          echo "" >> performance-report.md

          echo "Full reports available in workflow artifacts." >> performance-report.md

      - name: Store performance report
        uses: actions/upload-artifact@v4
        with:
          name: performance-report
          path: performance-report.md
          retention-days: 90
